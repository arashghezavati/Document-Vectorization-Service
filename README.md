# ğŸ“– AI-Powered Document Processing & Chatbot Service

The system allows users to upload documents, perform AI-powered searches, and receive intelligent insights. It enhances document retrieval by providing accurate, context-aware responses using fine-tuned AI models, making it easy to find relevant information quickly and efficiently.

---

## ğŸ”¹ How It Works:

âœ” **Google Gemini AI** generates **vector embeddings** for document storage & retrieval.  
âœ” **Fine-Tuned LLM (Mistral-7B/Phi-2)** is used for chatbot responses, ensuring **accurate and domain-specific answers**.  
âœ” **Retrieval-Augmented Generation (RAG)** dynamically **retrieves relevant documents** before generating responses.

---

## ğŸ›  System Architecture

Below is a high-level architecture diagram of the system:

```mermaid
flowchart TD
    subgraph User
        A[User Interface] -->|Uploads Documents| B[Backend API]
        A -->|Asks Questions| B
    end

    subgraph Backend
        B -->|Stores Documents| C[ChromaDB]
        B -->|Fetches Documents| C
        B -->|Generates Embeddings| D[Google Gemini API]
        B -->|Generates Responses| E[Fine-Tuned LLM]
    end

    subgraph Storage
        C -->|Indexes Vectors| F[Vector Database]
    end
```

---

## ğŸ”„ Workflow Diagram

The following diagram illustrates the workflow for document processing and chatbot interaction:

```mermaid
sequenceDiagram
    participant User
    participant Frontend
    participant Backend
    participant ChromaDB
    participant AI

    User->>Frontend: Upload Document
    Frontend->>Backend: Send Document
    Backend->>ChromaDB: Store Document Embeddings
    Backend->>AI: Generate Embeddings (Google Gemini)
    User->>Frontend: Ask Question
    Frontend->>Backend: Send Query
    Backend->>ChromaDB: Retrieve Relevant Documents
    Backend->>AI: Generate Response (Fine-Tuned LLM)
    AI->>Backend: Return Response
    Backend->>Frontend: Send Response
    Frontend->>User: Display Answer
```

---

## ğŸš€ Features & Benefits

### ğŸ“– AI-Powered Document Search (Google Gemini AI)

âœ… **Smart Semantic Search** â€“ Finds relevant documents **even without exact keyword matches**.  
âœ… **Multi-Format Support** â€“ Works with **PDF, DOCX, TXT, HTML**.  
âœ… **Fast Retrieval** â€“ Uses **ChromaDB** for vector-based document indexing.

---

### ğŸ¤– AI Chatbot (Fine-Tuned LLM)

âœ… **Fine-Tuned LLM Integration** â€“ Trained on **custom business data** for domain-specific accuracy.  
âœ… **User-Specific Responses** â€“ Chatbot provides answers based on **retrieved documents**.  
âœ… **Two AI Modes**:  
 - **Google Gemini AI**: Used for **vector embeddings & document retrieval**.  
 - **Fine-Tuned LLM**: Used for **chatbot responses with improved accuracy**.

---

### ğŸ“¤ Document & Folder Management

âœ… **Upload Documents** via a simple UI.  
âœ… **Organize Documents** into folders.  
âœ… **Custom Document Names** during upload.  
âœ… **Delete & Manage** documents as needed.

---

## ğŸ”§ Fine-Tuning on Custom Data (Mistral-7B/Phi-2)

The chatbot **uses a fine-tuned model** instead of generic AI responses to improve accuracy.  
The fine-tuning process includes:

âœ” **Dataset Curation** â€“ Preparing, cleaning, and structuring custom training data.  
âœ” **Hyperparameter Optimization** â€“ Adjusting batch size, learning rate, and training epochs.  
âœ” **Efficient Training** â€“ Using **LoRA (Low-Rank Adaptation)** to fine-tune only essential model parameters.

---

### ğŸ”¹ Retrieval-Augmented Generation (RAG)

The chatbot **retrieves documents dynamically** and generates responses **based on real-time data**, improving accuracy and relevance.

---

### ğŸ”¹ Model Distillation & Inference Optimization

âœ” **Model Distillation** â€“ Trained a **lighter version** of the model for faster responses.  
âœ” **Inference Optimization** â€“ Implemented **quantization** to reduce memory usage.  
âœ” **Batch Processing & Caching** â€“ Optimized **query efficiency**.

---

### ğŸ”¹ Use Your Own Fine-Tuned Model

- The **fine-tuning code is included** in this repo.
- You can **train a custom model**, upload it, and **replace the API key** to integrate your own fine-tuned LLM.

---

## âš¡ Quick Start Guide

### 1ï¸âƒ£ Clone & Setup

```sh
# Clone the repository
git clone https://github.com/arashghezavati/Document-Vectorization-Service.git
cd Document-Vectorization-Service

# Create a virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
.\venv\Scripts\activate   # Windows

# Install dependencies
pip install -r python-services/requirements.txt
```

---

### 2ï¸âƒ£ Configure API Keys & Fine-Tuned Model

Create a `.env` file in the root directory and add the following:

```env
GOOGLE_GEMINI_API_KEY=your_gemini_api_key
GEMINI_MODEL=gemini-2.0-flash

FINE_TUNED_LLM_API=your_fine_tuned_llm_api_endpoint
FINE_TUNED_LLM_MODEL_NAME=mistral-7B-finetuned
JWT_SECRET_KEY=your_jwt_secret_key
EMBEDDING_DIMENSION=768
EMBEDDING_MODEL=text-embedding-004
```

If you're using your own fine-tuned model, upload it and replace the API endpoint.

---

### 3ï¸âƒ£ Start the AI Chatbot API

```sh
# Navigate to the python-services directory
cd python-services

# Start the FastAPI server
python run_server.py
```

ğŸ“Œ Backend URL: `http://localhost:8000`  
ğŸ“Œ API Docs: `http://localhost:8000/docs`

---

### 4ï¸âƒ£ Open the Application UI

1. Open `http://localhost:3000` in your browser.
2. Register or log in to your account.
3. Navigate through the interface:
   - **Dashboard**: Overview of documents.
   - **Documents**: Upload & manage files.
   - **Chat**: Ask AI about stored business data.

---

## ğŸ— Fine-Tuning Your Own Model

If you want to fine-tune a new model, follow these steps:

### 1ï¸âƒ£ Prepare Training Data

Store your training data as a CSV or JSON file inside `fine-tuning/`.  
Example structure:

```json
[
  { "text": "How does Express Entry work in Canada?" },
  { "text": "Explain the steps for applying for a visa." }
]
```

---

### 2ï¸âƒ£ Train a New Model

```sh
cd fine-tuning

# Install fine-tuning dependencies
pip install -r requirements.txt

# Start training (Adjust hyperparameters in fine_tune.py)
python fine_tune.py
```

The model will be saved in `fine-tuning/your-fine-tuned-model`.

---

### 3ï¸âƒ£ Deploy the Fine-Tuned Model

1. Upload the model to a hosting service (Hugging Face, AWS, etc.).
2. Replace `FINE_TUNED_LLM_API` in `.env` with your API endpoint.

---

## ğŸ“š Use Cases

### ğŸ”¹ Business Knowledge Management

âœ” Store internal company documents and search instantly.  
âœ” Employees can ask AI about policies, reports, and more.

---

### ğŸ”¹ Legal & Compliance

âœ” Quickly retrieve legal documents, case studies, and contracts.  
âœ” Get AI-powered summaries for faster decision-making.

---

### ğŸ”¹ Customer Support Automation

âœ” Automate responses by searching FAQs & knowledge bases.  
âœ” Reduce manual support workload.

---

## ğŸ›  Technical Stack

| Component      | Technology Used                    |
| -------------- | ---------------------------------- |
| **Backend**    | FastAPI, ChromaDB                  |
| **AI Models**  | Google Gemini API, Fine-Tuned LLM  |
| **Frontend**   | React.js                           |
| **Auth**       | JWT-based authentication           |
| **Storage**    | ChromaDB (Vector Database)         |
| **Processing** | PyPDF2, python-docx, BeautifulSoup |

---

## ğŸ¤ Contributing

We welcome contributions! To contribute:

1ï¸âƒ£ Fork the repository  
2ï¸âƒ£ Create a feature branch (`git checkout -b feature/your-feature`)  
3ï¸âƒ£ Commit your changes (`git commit -m "Add new feature"`)  
4ï¸âƒ£ Push to the branch (`git push origin feature/your-feature`)  
5ï¸âƒ£ Open a Pull Request

---

## ğŸ“© Support

For support, please open an issue in the GitHub repository or contact the maintainers directly.
